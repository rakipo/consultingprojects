# Performance Analysis and Optimization

## Why Processing Takes Time

### 1. Real Satellite Data Processing
- **Sentinel Hub API Calls**: Each request involves server-side processing
- **Satellite Data**: Processing terabytes of raw satellite data
- **Cloud Filtering**: Finding images with acceptable cloud coverage
- **Index Calculations**: Computing vegetation, built-up, and water indices

### 2. Typical Processing Times
- **Single Image Request**: 30-60 seconds
- **Change Detection**: 1-2 minutes (2 images + statistics)
- **Visual Comparison**: 1-2 minutes (2 images + processing)
- **Continuous Monitoring**: 5-10 minutes (multiple periods)

### 3. Factors Affecting Speed
- **Image Resolution**: Higher resolution = longer processing
- **Date Range**: Longer periods = more data to process
- **Cloud Coverage**: Lower cloud tolerance = more processing time
- **Area Size**: Larger areas = more pixels to process
- **Network Speed**: Internet connection affects download time

## Optimization Strategies

### 1. Reduce Resolution
```yaml
# In sentinel_hub_config.yml
image_processing:
  resolution: 20  # Instead of 10 (faster but less detailed)
```

### 2. Increase Cloud Tolerance
```yaml
image_processing:
  max_cloud_coverage: 50.0  # Instead of 20.0 (more images available)
```

### 3. Use Caching
```python
# Add caching to avoid re-downloading same data
import hashlib
import pickle
import os

def get_cached_image(date_range, bbox):
    cache_key = hashlib.md5(f"{date_range}_{bbox}".encode()).hexdigest()
    cache_file = f"cache/{cache_key}.pkl"
    
    if os.path.exists(cache_file):
        with open(cache_file, 'rb') as f:
            return pickle.load(f)
    
    # Download and cache
    image = download_image(date_range, bbox)
    os.makedirs("cache", exist_ok=True)
    with open(cache_file, 'wb') as f:
        pickle.dump(image, f)
    
    return image
```

### 4. Parallel Processing
```python
# Process multiple date ranges in parallel
from concurrent.futures import ThreadPoolExecutor

def parallel_analysis(date_ranges):
    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(analyze_period, date_range) 
                  for date_range in date_ranges]
        results = [future.result() for future in futures]
    return results
```

### 5. Use Mock Data for Testing
```python
# For development/testing, use mock data
def get_mock_satellite_image(date_range):
    # Generate synthetic satellite data
    return np.random.rand(100, 100, 3)  # Mock RGB image
```

## Monitoring Progress

### Add Progress Indicators
```python
import time
from tqdm import tqdm

def analyze_with_progress():
    print("üîÑ Starting analysis...")
    
    with tqdm(total=4, desc="Processing") as pbar:
        # Step 1: Get before image
        print("üì° Downloading before period image...")
        before_img = get_satellite_image(before_range)
        pbar.update(1)
        
        # Step 2: Get after image
        print("üì° Downloading after period image...")
        after_img = get_satellite_image(after_range)
        pbar.update(1)
        
        # Step 3: Calculate statistics
        print("üìä Calculating statistics...")
        stats = calculate_statistics(before_range)
        pbar.update(1)
        
        # Step 4: Generate comparison
        print("üñºÔ∏è Generating visual comparison...")
        generate_comparison(before_img, after_img)
        pbar.update(1)
    
    print("‚úÖ Analysis complete!")
```

## Expected Performance

### Development/Testing
- **Mock Data**: < 5 seconds
- **Small Areas**: 30-60 seconds
- **Single Analysis**: 1-2 minutes

### Production Use
- **Large Areas**: 2-5 minutes
- **Continuous Monitoring**: 5-15 minutes
- **Batch Processing**: 10-30 minutes

## Best Practices

1. **Start Small**: Test with small areas first
2. **Use Caching**: Implement caching for repeated analyses
3. **Monitor Progress**: Add progress indicators
4. **Optimize Parameters**: Adjust resolution and cloud coverage
5. **Batch Operations**: Group multiple analyses together
6. **Background Processing**: Run long operations in background

## Troubleshooting Slow Performance

### Check Network
```bash
# Test API connectivity
curl -I https://services.sentinel-hub.com/api/v1/process

# Check download speed
wget --report-speed=bits https://services.sentinel-hub.com/api/v1/process
```

### Monitor Resources
```python
import psutil
import time

def monitor_resources():
    while processing:
        cpu = psutil.cpu_percent()
        memory = psutil.virtual_memory().percent
        print(f"CPU: {cpu}%, Memory: {memory}%")
        time.sleep(5)
```

### Optimize Configuration
```yaml
# Faster processing configuration
image_processing:
  resolution: 20  # Lower resolution
  max_cloud_coverage: 50.0  # Higher cloud tolerance

monitoring:
  default_interval_days: 60  # Longer intervals
  period_length_days: 30  # Shorter periods
```
