#!/usr/bin/env python3
"""PostgreSQL to Neo4j via Claude transformation pipeline"""

import json
import psycopg2
from neo4j import GraphDatabase
import requests

class GraphIngestion:
    def __init__(self, pg_conn, neo4j_uri, neo4j_auth, claude_api_key):
        self.pg = psycopg2.connect(pg_conn)
        self.neo4j = GraphDatabase.driver(neo4j_uri, auth=neo4j_auth)
        self.claude_key = claude_api_key
        
    def extract_articles(self, days=7):
        """Extract articles from PostgreSQL"""
        with self.pg.cursor() as cur:
            cur.execute("""
                SELECT id, title, content, tags, author, publish_date, domain
                FROM structured_content 
                WHERE publish_date > NOW() - INTERVAL '%s days'
            """, (days,))
            
            return [{
                'id': row[0], 'title': row[1], 'content': row[2],
                'tags': row[3], 'author': row[4], 
                'publish_date': row[5].isoformat(), 'domain': row[6]
            } for row in cur.fetchall()]
    
    def transform_to_graph(self, article):
        """Transform article via Claude API"""
        prompt = f"""Convert article to Neo4j graph format.

INPUT: {json.dumps(article)}

OUTPUT (JSON only):
Extract entities from content. Use exact property names. Return valid JSON only."""
        
        response = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers={
                "Content-Type": "application/json",
                "x-api-key": self.claude_key
            },
            json={
                "model": "claude-sonnet-4-20250514",
                "max_tokens": 2000,
                "messages": [{"role": "user", "content": prompt}]
            }
        )
        
        return json.loads(response.json()['content'][0]['text'])
    
    def ingest_graph(self, graph_data):
        """Insert nodes and relationships into Neo4j"""
        def tx_ingest(tx):
            # Create nodes
            for node in graph_data['nodes']:
                label = node['label']
                props = node['properties']
                prop_str = ', '.join(f"{k}: ${k}" for k in props)
                cypher = f"MERGE (n:{label} {{{prop_str}}})"
                tx.run(cypher, **props)
            
            # Create relationships  
            for rel in graph_data['relationships']:
                from_label, to_label = rel['from'], rel['to']
                rel_type = rel['type']
                
                # Match by first property (usually id/name)
                cypher = f"""
                MATCH (a:{from_label}), (b:{to_label})
                WHERE a.{list(graph_data['nodes'][0]['properties'].keys())[0]} = $from_val
                  AND b.{list(graph_data['nodes'][1]['properties'].keys())[0]} = $to_val
                MERGE (a)-[:{rel_type}]->(b)
                """
                # This is simplified - in production, match on specific node identifiers
        
        with self.neo4j.session() as session:
            session.write_transaction(tx_ingest)
    
    def run_pipeline(self):
        """Execute full pipeline"""
        articles = self.extract_articles()
        
        for article in articles:
            try:
                graph_data = self.transform_to_graph(article)
                self.ingest_graph(graph_data)
                print(f"✓ Processed: {article['id']}")
            except Exception as e:
                print(f"✗ Failed {article['id']}: {e}")
    
    def close(self):
        self.pg.close()
        self.neo4j.close()

# Usage
if __name__ == "__main__":
    pipeline = GraphIngestion(
        pg_conn="postgresql://user:pass@localhost/db",
        neo4j_uri="bolt://localhost:7687", 
        neo4j_auth=("neo4j", "password"),
        claude_api_key="your-claude-key"
    )
    
    pipeline.run_pipeline()
    pipeline.close()